# LLMEngineering

The scope of the project is to get familiarized with LLM Engineering and Observability by explaoring various tools and methodologies.
A key focus is on Langfuse, a powerful observability platform for LLM applications, along with integrating external pipelines such as DeepEval and Phoenix evaluation.

The project involves:
* Understanding Langfuse and its capabilities in logging, monitoring and nalyzing LLM performance
* Implementing DeepEval and Phoenix evaluation for assessong LLM generated responses.
* Comparing different evaluation approaches and identifying the best practoces for effective observability.
* Building a simple framework ro seamlessly integrate these tools for effecient debugging, monitoring and performance optimization.

Please refer the below links for langfuse local setup and External evaluation integration:
* Langfuse local setup : https://langfuse.com/self-hosting/local
* Integrating External Evaluation pipeline with Langfuse : https://langfuse.com/docs/scores/external-evaluation-pipelines
